# -*- coding: utf-8 -*-
"""(4.1) Life Expectancy Prediction MLR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X5PZdyfpFgs04sYwM2-dTneD668oaxgI
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from jupyterthemes import jtplot
jtplot.style(theme = 'monokai', context = 'notebook', ticks = True, grid = False)

life_expectancy_df = pd.read_csv('C:/Users/Annie Keerthana/Downloads/Life_Expectancy_Data.csv')
life_expectancy_df

life_expectancy_df.head(7)

sns.heatmap(life_expectancy_df.isnull(), yticklabels = False, cbar = False, cmap="Blues")
#areas highlighted in blue are the missing values. This is to easily understand the data and interpret it.

# Check the dataframe info
life_expectancy_df.info()

life_expectancy_df.describe()

# Plot the histogram
life_expectancy_df.hist(bins = 30, figsize = (20, 20), color = 'gold');

# Plot pairplot: combination of all the sctterplots of the dataframe
plt.figure(figsize = (20,20))
sns.pairplot(life_expectancy_df)

sns.scatterplot(data = life_expectancy_df, x = 'Schooling', y = 'Life expectancy ')
#As schooling increases, the life expectancy also increases.

sns.scatterplot(data = life_expectancy_df, x = 'GDP', y = 'Life expectancy ')
#Life expectancy increases as GDP increases

sns.scatterplot(data = life_expectancy_df, x = 'Income composition of resources', y = 'Life expectancy ')
# How productive resources are used

sns.scatterplot(data = life_expectancy_df, x = ' HIV/AIDS', y = 'Life expectancy ')
# HIV/AIDs death rate increases, life expectancy is reduced

plt.figure(figsize=(20,20))
corr_matrix = life_expectancy_df.corr()
sns.heatmap(corr_matrix, annot=True)
plt.show()

life_expectancy_df

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Assuming life_expectancy_df is your DataFrame

# Select only the numeric columns
numeric_df = life_expectancy_df.select_dtypes(include=[np.number])

# Calculate the correlation matrix
corr_matrix = numeric_df.corr()

# Plot the heatmap
plt.figure(figsize=(20, 20))
sns.heatmap(corr_matrix, annot=True)
plt.show()

life_expectancy_df

# Checking the unique values in country to consider it as a categorical variable
life_expectancy_df['Status'].nunique()

life_expectancy_df = pd.get_dummies(life_expectancy_df, columns = ['Status'])

life_expectancy_df

life_expectancy_df = life_expectancy_df.apply(lambda x: x.fillna(x.mean()),axis=0)

life_expectancy_df.isnull().sum()[np.where(life_expectancy_df.isnull().sum() != 0)[0]]

life_expectancy_df['Life expectancy '].max()

X = life_expectancy_df.drop(columns = ['Life expectancy '])
y = life_expectancy_df[['Life expectancy ']]

X

y

X.shape

y.shape

# Convert the data type to float32
X = np.array(X).astype('float32')
y = np.array(y).astype('float32')

# Only take the numerical variables and scale them
X

# split the data into test and train sets
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)

# Scale the data
from sklearn.preprocessing import StandardScaler

scaler_X = StandardScaler()
X_train = scaler_X.fit_transform(X_train)
X_test = scaler_X.transform(X_test)

scaler_y = StandardScaler()
y_train = scaler_y.fit_transform(y_train)
y_test = scaler_y.transform(y_test)

# using linear regression model
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, accuracy_score

regresssion_model_sklearn = LinearRegression(fit_intercept = True)
regresssion_model_sklearn.fit(X_train, y_train)

regresssion_model_sklearn_accuracy = regresssion_model_sklearn.score(X_test, y_test)
regresssion_model_sklearn_accuracy

#y = mx + b
print('Linear Model Coefficient (m): ', regresssion_model_sklearn.coef_)
print('Linear Model Coefficient (b): ', regresssion_model_sklearn.intercept_)

# Make prediction

y_predict = regresssion_model_sklearn.predict(X_test)

y_predict

# Plot the scaled result

plt.plot(y_test, y_predict, "^", color = 'gold')
plt.xlabel('Model Predictions')
plt.ylabel('True Values')

y_predict_orig = scaler_y.inverse_transform(y_predict)
y_test_orig = scaler_y.inverse_transform(y_test)

# Plot the original values

plt.plot(y_test_orig, y_predict_orig, "^", color = 'green')
plt.xlabel('Model Predictions')
plt.ylabel('True Values')

# Plot the Key Performance Indicators KPIs

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from math import sqrt

k = X_test.shape[1]
n = len(X_test)
RMSE = float(format(np.sqrt(mean_squared_error(y_test_orig, y_predict_orig)),'.3f'))
MSE = mean_squared_error(y_test_orig, y_predict_orig)
MAE = mean_absolute_error(y_test_orig, y_predict_orig)
r2 = r2_score(y_test_orig, y_predict_orig)
adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)

print('RMSE =',RMSE, '\nMSE =',MSE, '\nMAE =',MAE, '\nR2 =', r2, '\nAdjusted R2 =', adj_r2)